{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab19013",
   "metadata": {},
   "source": [
    "# 用决策树做已婚情况推断\n",
    " 对于该数据集我采用的模型是决策树模型。决策树模型的优点是计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。缺点是可能会产生过度匹配的问题。决策树模型是非常适合解决该问题的模型。\n",
    " ## 决策树模型的一般流程\n",
    "收集数据：数据已经直接给出\n",
    "准备数据：构造算法只适用于标称型数据，因此数值型数据必须离散化。\n",
    "分析数据：可以使用任何方法，构造完树以后，我们应该检查图形是否符合预期。\n",
    "训练算法：构造数的数据结构。\n",
    "测试算法：使用经验树计算错误概率\n",
    " ## 处理数据\n",
    " 给出数据的维度依次是CustomerID、ItemID、Sex、Age、Profession、CityType、YearsInCity、YearsInCity、Married、ItemCategory1、ItemCategory2、ItemCategory3、Amount，Married是目标数据，即要通过模型训练来判定的数据，Sex、Age、Profession、CityType、YearsInCity、YearsInCity是离散型数据，可以直接使用，ItemCategory1、ItemCategory2、ItemCategory3、Amount是数值型数据需要进行离散化处理。CustomerID、ItemID不适合使用。\n",
    " 商品分类 的离散化处理可以通过判定每个订单购买最多的商品类型来进行离散化处理，输出结果为商品类型['1','2','3']。Amount的离散化处理可以先用散点图看Amount的散点图分布情况然后选定一个大概的界限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ef8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mxnet import autograd, gluon, nd\n",
    "data=pd.read_csv(\"H:\\sjwj\\cs.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da008ad5",
   "metadata": {},
   "source": [
    "选定训练集。先取得所有married值未缺失的数据项。以经验来看，['Sex','Age','Profession','CityType','YearsInCity']作为离散值属性看起来是对结果影响最大的，所以我首先选择的数据集包含这些维度作为训练集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33c7642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'Age', 'Profession', 'CityType', 'YearsInCity']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_train = pd.DataFrame(data[(data['Married'] == 0) | (data['Married'] == 1)]).values\n",
    "dataSet=data_train[:,2:8]\n",
    "labels=['Sex','Age','Profession','CityType','YearsInCity']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8735eb",
   "metadata": {},
   "source": [
    " ## 构建决策树\n",
    "使用ID3算法构建决策树\n",
    "第一步先计算信息熵，信息熵计算公式：\n",
    "$$H = -\\sum_{i=1}^n p\\left( x_i\\right ) \\log_2p\\left( x_i\\right ),$$\n",
    "其中$p\\left( x_i\\right )$是这个类型在总数据集中出现的概率\n",
    "接下来用信息熵去衡量数据集的无序程度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db39f95b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)  \n",
    "    labelCounts = {}   \n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1] \n",
    "        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0  \n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob,2) \n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fca0f9",
   "metadata": {},
   "source": [
    "遍历所有特征，对于特征A：\n",
    "计算特征A对数据集D的经验条件熵H(D|A)\n",
    "计算特征A的信息增益g(D,A)=H(D)-H(D|A)\n",
    "选择信息增益最大的特征作为当前分裂特征。先按照特征划分数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c6fd31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet,axis,value):\n",
    "    retDataSet=[]\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            featVec=list(featVec)\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ec342",
   "metadata": {},
   "source": [
    "选择出信息增益最高的划分方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8caa4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1      \n",
    "    baseEntropy = calcShannonEnt(dataSet)  \n",
    "    bestInfoGain = 0.0; bestFeature = -1   \n",
    "    for i in range(numFeatures):        \n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)       \n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals: \n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy     \n",
    "        if (infoGain > bestInfoGain):      \n",
    "            bestInfoGain = infoGain        \n",
    "            bestFeature = i\n",
    "    return bestFeature        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ab829",
   "metadata": {},
   "source": [
    "## 递归构建决策树\n",
    "函数使用分类名称的列表，然后创创建键值为classList中唯一值得数据字典，字典对象存储了classList中每个类标签出现的频率，利用operator操作键值排序字典，返回出现次数最多的分类名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134ba482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae6f264",
   "metadata": {},
   "source": [
    "已经给出了从数据集构造决策树算法所需要的子功能模块，工作原理如下：\n",
    "得到原始数据集，然后基于最好的属性值划分数据集，由于特征值可能多于两个，因此可能存在大于两个分支的数据集划分。第一次划分之后，数据将被乡下传递到树分支的下一个节点，在这个节点上，可以再次划分数据。\n",
    "递归结束的条件是：程序遍历完所有划分数据集的属性，或者每个分支下的所有的实例都具有相同的分类。如果所有实例具有相同的分类，则得到一个叶子节点或者终止块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3120a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) <= 1: \n",
    "        return majorityCnt(classList) \n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    if bestFeat==-1:\n",
    "        return classList[0]\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}} \n",
    "    del(labels[bestFeat]) \n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)\n",
    "    return myTree\n",
    "myTree=createTree(dataSet,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164313cd",
   "metadata": {},
   "source": [
    "完成训练后，用决策树执行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02eb6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用决策树的分类函数\n",
    "def classify(inputTree,featLabels,testVec):\n",
    "    inputTree_keys = list(inputTree.keys())\n",
    "    firstStr = inputTree_keys[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    try:\n",
    "        key = testVec[featIndex]\n",
    "        valueOfFeat = secondDict[key]\n",
    "    except:\n",
    "        return 0\n",
    "    if isinstance(valueOfFeat, dict): \n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else: classLabel = valueOfFeat\n",
    "    return classLabel"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9d2e470e",
   "metadata": {},
   "source": [
    "## 模型评估\n",
    "采用f1score的模型评估法\n",
    "精确度：precision，正确预测为正的，占全部预测为正的比例，TP / (TP+FP)\n",
    "召回率：recall，正确预测为正的，占全部实际为正的比例，TP / (TP+FN)\n",
    "假设有一个大小为1000的带布尔标签数据集，里面的“真”样本只有100不到，剩下都是假样本。假设训练一个模型，不管输入什么数据，它只给出“假”的预测，那么正确率依旧是90%以上，很明显，这个时候准确率accuracy就失去它的作用。因此，查全率和查准率一般用在倾斜数据集的时候。\n",
    "Precision和Recall指标有的时候是矛盾的，F-Measure综合这二者指标的评估指标，用于综合反映整体的指标。F-Measure是Precision和Recall加权调和平均, a为权重因子，当a = 1时，F值变为最常见的F1了，代表精确率和召回率的权重一样(fl_score)\n",
    "![image.png](attachment:image.png)\n",
    "F1 值，也称为综合分类率：F1=2 * precision * recall/(precision+recall),为了综合多个类别的分类情况，评测系统整体性能，经常采用的还有微平均F1(micro-averaging)和宏平均F1(macro-averaging)两种指标。宏平均F1与微平均F1 是以两种不同的平均方式求的全局的F1指标。其中宏平均 F1 的计算方法先对每个类别单独计算F1值，再取这些F1值的算术平均值作为全局指标。而微平均F1的计算方法是先累加计算各个类别的a、b、c、d的值，再由这些值求出F1值。 由两种平均F1的计算方式不难看出，宏平均F1平等对待每一个类别，所以它的值主要受到稀有类别的影响，而微平均F1平等考虑文档集中的每一个文档，所以它的值受到常见类别的影响比较大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfdab904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.6773,precision 0.7706, f1 score 0.7209\n"
     ]
    }
   ],
   "source": [
    "labels=['Sex','Age','Profession','CityType','YearsInCity']\n",
    "tp,fp,tn,fn=0,0,0,0\n",
    "recall,precision,f1_score=0,0,0\n",
    "for featVec in dataSet:\n",
    "    clf=classify(myTree,labels,featVec)\n",
    "    if clf==1 and featVec[-1]==1:\n",
    "        tp+=1\n",
    "    if clf==0 and featVec[-1]==0:\n",
    "        tn+=1\n",
    "    if clf==1 and featVec[-1]==0:\n",
    "        fp+=1\n",
    "    if clf==0 and featVec[-1]==1:\n",
    "        fn+=1\n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "f1_score=2 * precision * recall/(precision+recall)\n",
    "print('recall %.4f,precision %.4f, f1 score %.4f'%(recall,precision,f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
